{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "509f6ca9",
   "metadata": {},
   "source": [
    "- Hyperparameter Tuning\n",
    "- mixed precision tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8342aa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "2.12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.keras.__version__)\n",
    "print(tf.__version__)\n",
    "tf.config.list_physical_devices('GPU')\n",
    "#keras.mixed_precision.set_global_policy(\"mixed_float16\") # turn on mixed precision for faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa0652f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = '/home/lndr/Development/FER/AffectNet_sorted/train_set'\n",
    "test_img_dir = '/home/lndr/Development/FER/AffectNet_sorted/val_set'\n",
    "#train_img_dir = '/home/lndr/Development/FER/AffectNet_sorted_balanced_small/train_set'\n",
    "#test_img_dir = '/home/lndr/Development/FER/AffectNet_sorted_balanced_small/val_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd88c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def load_data(train_img_dir, test_img_dir, image_size=(224,224), batch_size=32, validation_split=0.2):\n",
    "\n",
    "    train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        train_img_dir,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        color_mode='rgb',\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        shuffle=True,\n",
    "        seed=random.randint(0,1000),\n",
    "        validation_split=validation_split,\n",
    "        subset='both'\n",
    "    )\n",
    "\n",
    "    test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        test_img_dir,\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        color_mode='rgb',\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        shuffle=True,\n",
    "        seed=random.randint(0,1000),\n",
    "        validation_split=None\n",
    "    )\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce7ad7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    accuracy = history.history[\"accuracy\"]\n",
    "    val_accuracy = history.history[\"val_accuracy\"]\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "    plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "    plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df3d4d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.01557266066902349,\n",
       " 1: 0.008674533310511956,\n",
       " 2: 0.045798632897304084,\n",
       " 3: 0.08275283143594497,\n",
       " 4: 0.18281395342308948,\n",
       " 5: 0.3065967380837404,\n",
       " 6: 0.04686067819839501,\n",
       " 7: 0.31092997198199057}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "classes = {0: 'neutral', \n",
    "           1: 'happiness', \n",
    "           2: 'sadness', \n",
    "           3: 'surprise', \n",
    "           4: 'fear', \n",
    "           5: 'disgust', \n",
    "           6: 'anger', \n",
    "           7: 'contempt'}\n",
    "\n",
    "# calculate weights on class distribution from 0-7\n",
    "total_images = 287_652\n",
    "images_per_class = [74_874, 134_415, 25_459, 14_090, 6_378, 3_803, 24_882, 3_750]\n",
    "class_distribution = [d/total_images for d in images_per_class]\n",
    "# inverse class distribution for weights (lower dist = higher weight)\n",
    "class_weights = [1.0 / dist for dist in class_distribution]\n",
    "# normalize\n",
    "class_weights_normalized = class_weights / np.sum(class_weights)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights_normalized)}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc19101",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73005837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import keras_tuner\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomBrightness(.2),\n",
    "        layers.RandomContrast(.2),\n",
    "        layers.RandomZoom(.3, fill_mode=\"constant\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def build(self, hp):\n",
    "        # Load Base Model\n",
    "        vgg_model = VGGFace(model=\"resnet50\", include_top=False, input_shape=(224, 224, 3))\n",
    "        vgg_model.trainable = True\n",
    "        for layer in vgg_model.layers[:-33]: # starting with res5\n",
    "            layer.trainable = False\n",
    "        \n",
    "        inputs = keras.Input(shape=(224, 224, 3))\n",
    "        x = data_augmentation(inputs)\n",
    "        x = keras.applications.resnet.preprocess_input(x)\n",
    "        x = vgg_model(x)\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "        # Test dense units\n",
    "        x = layers.Dense(units=hp.Choice(\"units\", [1024, 2048, 4096]), activation=\"relu\")(x)\n",
    "        outputs = layers.Dense(8, activation='softmax', name='classifier', dtype=\"float32\")(x)\n",
    "        return keras.Model(inputs, outputs)\n",
    "    \n",
    "    def fit(self, hp, model, train_img_dir, test_img_dir, callbacks=None, **kwargs):\n",
    "        # Test batch size\n",
    "        batch_size = hp.Int(\"batch_size\", 32, 128, step=32, default=64)\n",
    "        (train_dataset, val_dataset), test_dataset = load_data(train_img_dir, test_img_dir, batch_size=batch_size)\n",
    "        \n",
    "        # Define optimizer, test learning rate\n",
    "        optimizer = keras.optimizers.Adam(\n",
    "            hp.Float(\"learning_rate\", 1e-8, 1e-2, sampling=\"log\", default=1e-3)\n",
    "        )\n",
    "        loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        \n",
    "        # Metric to track val loss (mean of all batches per epoch)\n",
    "        epoch_loss_metric = keras.metrics.Mean()\n",
    "        \n",
    "        # Run train step\n",
    "        @tf.function\n",
    "        def run_train_step(images, labels):\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(images)\n",
    "                loss = loss_fn(labels, logits)\n",
    "                # Add any regularization losses.\n",
    "                if model.losses:\n",
    "                    loss += tf.math.add_n(model.losses)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # Function to run the validation step.\n",
    "        @tf.function\n",
    "        def run_val_step(images, labels):\n",
    "            logits = model(images)\n",
    "            loss = loss_fn(labels, logits)\n",
    "            # Update the metric.\n",
    "            epoch_loss_metric.update_state(loss)\n",
    "\n",
    "        # Assign the model to the callbacks.\n",
    "        for callback in callbacks:\n",
    "            callback.model = model\n",
    "\n",
    "        # Record the best validation loss value\n",
    "        best_epoch_loss = float(\"inf\")\n",
    "        \n",
    "        # The custom training loop.\n",
    "        for epoch in range(25):\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "\n",
    "            # Iterate the training data to run the training step.\n",
    "            for images, labels in train_dataset:\n",
    "                run_train_step(images, labels)\n",
    "\n",
    "            # Iterate the validation data to run the validation step.\n",
    "            for images, labels in val_dataset:\n",
    "                run_val_step(images, labels)\n",
    "\n",
    "            # Calling the callbacks after epoch.\n",
    "            epoch_loss = float(epoch_loss_metric.result().numpy())\n",
    "            for callback in callbacks:\n",
    "                # The \"my_metric\" is the objective passed to the tuner.\n",
    "                callback.on_epoch_end(epoch, logs={\"val_loss\": epoch_loss})\n",
    "            epoch_loss_metric.reset_states()\n",
    "\n",
    "            print(f\"Epoch loss: {epoch_loss}\")\n",
    "            best_epoch_loss = min(best_epoch_loss, epoch_loss)\n",
    "\n",
    "        # Return the evaluation metric value.\n",
    "        return best_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57d912ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [01h 47m 01s]\n",
      "val_loss: 0.8430920243263245\n",
      "\n",
      "Best val_loss So Far: 0.7732552886009216\n",
      "Total elapsed time: 03h 36m 51s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    objective=keras_tuner.Objective(\"val_loss\", \"min\"),\n",
    "    max_trials=2,\n",
    "    hypermodel=MyHyperModel(),\n",
    "    directory=\"results\",\n",
    "    project_name=\"custom_training\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "tuner.search(train_img_dir, test_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5184af4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': 2048, 'batch_size': 64, 'learning_rate': 0.001}\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem (S  (None, 224, 224, 3)      0         \n",
      " licingOpLambda)                                                 \n",
      "                                                                 \n",
      " tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " vggface_resnet50 (Functiona  (None, 1, 1, 2048)       23561152  \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              4196352   \n",
      "                                                                 \n",
      " classifier (Dense)          (None, 8)                 16392     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,773,896\n",
      "Trainable params: 19,177,480\n",
      "Non-trainable params: 8,596,416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d90b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 287651 files belonging to 8 classes.\n",
      "Using 230121 files for training.\n",
      "Using 57530 files for validation.\n",
      "Found 3999 files belonging to 8 classes.\n",
      "125/125 [==============================] - 5s 34ms/step - loss: 1.7427 - accuracy: 0.4259\n",
      "Test accuracy: 0.426\n"
     ]
    }
   ],
   "source": [
    "best_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss = \"sparse_categorical_crossentropy\",\n",
    "              metrics = [\"accuracy\"])\n",
    "\n",
    "(train_dataset, val_dataset), test_dataset = load_data(train_img_dir, test_img_dir, batch_size=32)\n",
    "test_loss, test_acc = best_model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ab2dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40153b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 287651 files belonging to 8 classes.\n",
      "Using 230121 files for training.\n",
      "Using 57530 files for validation.\n",
      "Found 3999 files belonging to 8 classes.\n",
      "Saving model as: 20230918_15-09_fer_vggface-resnet50_finetuned_\n",
      "Epoch 1/50\n",
      "3596/3596 [==============================] - 374s 103ms/step - loss: 0.0490 - accuracy: 0.4922 - val_loss: 1.0929 - val_accuracy: 0.6022 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0433 - accuracy: 0.5326 - val_loss: 1.1836 - val_accuracy: 0.5535 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0417 - accuracy: 0.5462 - val_loss: 1.1396 - val_accuracy: 0.5592 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0405 - accuracy: 0.5564 - val_loss: 1.0720 - val_accuracy: 0.5917 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "3596/3596 [==============================] - 368s 102ms/step - loss: 0.0396 - accuracy: 0.5648 - val_loss: 1.1399 - val_accuracy: 0.5664 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0388 - accuracy: 0.5683 - val_loss: 1.0500 - val_accuracy: 0.6012 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "3596/3596 [==============================] - 369s 103ms/step - loss: 0.0383 - accuracy: 0.5711 - val_loss: 0.9490 - val_accuracy: 0.6668 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0379 - accuracy: 0.5749 - val_loss: 1.1426 - val_accuracy: 0.5670 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0376 - accuracy: 0.5770 - val_loss: 1.0698 - val_accuracy: 0.5839 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0371 - accuracy: 0.5785 - val_loss: 0.9979 - val_accuracy: 0.6128 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0368 - accuracy: 0.5807 - val_loss: 0.9024 - val_accuracy: 0.6657 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0364 - accuracy: 0.5843 - val_loss: 1.1521 - val_accuracy: 0.5823 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0362 - accuracy: 0.5856 - val_loss: 1.2077 - val_accuracy: 0.6224 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0358 - accuracy: 0.5862 - val_loss: 1.0440 - val_accuracy: 0.5845 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0357 - accuracy: 0.5894 - val_loss: 1.0560 - val_accuracy: 0.5971 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "3596/3596 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.5901\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0352 - accuracy: 0.5901 - val_loss: 1.0420 - val_accuracy: 0.6870 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "3596/3596 [==============================] - 369s 103ms/step - loss: 0.0335 - accuracy: 0.6035 - val_loss: 0.9568 - val_accuracy: 0.6301 - lr: 2.0000e-04\n",
      "Epoch 18/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0329 - accuracy: 0.6053 - val_loss: 0.9466 - val_accuracy: 0.6335 - lr: 2.0000e-04\n",
      "Epoch 19/50\n",
      "3596/3596 [==============================] - 368s 102ms/step - loss: 0.0328 - accuracy: 0.6078 - val_loss: 1.0204 - val_accuracy: 0.6150 - lr: 2.0000e-04\n",
      "Epoch 20/50\n",
      "3596/3596 [==============================] - 370s 103ms/step - loss: 0.0324 - accuracy: 0.6088 - val_loss: 0.9198 - val_accuracy: 0.6469 - lr: 2.0000e-04\n",
      "Epoch 21/50\n",
      "3596/3596 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.6098\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "3596/3596 [==============================] - 369s 103ms/step - loss: 0.0324 - accuracy: 0.6098 - val_loss: 0.9282 - val_accuracy: 0.6450 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import keras_tuner\n",
    "\n",
    "# Define Data Augmentation Layer\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomBrightness(.2),\n",
    "        layers.RandomContrast(.2),\n",
    "        layers.RandomZoom(.3, fill_mode=\"constant\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load Base Model\n",
    "vgg_model = VGGFace(model=\"resnet50\", include_top=False, input_shape=(224, 224, 3))\n",
    "vgg_model.trainable = True\n",
    "for layer in vgg_model.layers[:-33]: # starting with res5\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Add Head Model (Finetune)\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.applications.resnet.preprocess_input(x)\n",
    "x = vgg_model(x)\n",
    "x = layers.Flatten(name='flatten')(x)\n",
    "x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(8, activation='softmax', name='classifier', dtype=\"float32\")(x) # opt-out mixed precision for softmax layer\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "#vgg_model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss = \"sparse_categorical_crossentropy\",\n",
    "              metrics = [\"accuracy\"])\n",
    "\n",
    "# Load dataset\n",
    "(train_dataset, val_dataset), test_dataset = load_data(train_img_dir, test_img_dir, batch_size=32)\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.today()\n",
    "current_time = now.strftime(\"%Y%m%d_%H-%M\")\n",
    "model_name = f\"{current_time}_fer_vggface-resnet50_finetuned_\"\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_name + 'e{epoch:02d}-vloss{val_loss:.2f}.keras',\n",
    "        save_best_only=True,\n",
    "        #save_freq='epoch',\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", \n",
    "        patience=18),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", \n",
    "                                      factor=0.2, \n",
    "                                      patience=5, \n",
    "                                      verbose=1, \n",
    "                                      min_lr=1e-8)\n",
    "]\n",
    "\n",
    "# fit model\n",
    "print(f'Saving model as: {model_name}')\n",
    "history = model.fit(x=train_dataset, \n",
    "                    epochs=50, \n",
    "                    validation_data=val_dataset,\n",
    "                    class_weight=class_weights_dict,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c368e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 20230918_15-09_fer_vggface-resnet50_finetuned_\n",
      "63/63 [==============================] - 4s 65ms/step - loss: 1.2145 - accuracy: 0.5781\n",
      "Test accuracy: 0.578\n"
     ]
    }
   ],
   "source": [
    "model = history.model\n",
    "print(f\"Evaluating: {model_name}\")\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263fc9bd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7e0e1",
   "metadata": {},
   "source": [
    "## #1 Best Model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c3a9087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: 20230714_21-50_fer_vggface-resnet50_finetuned_\n",
      "125/125 [==============================] - 5s 40ms/step - loss: 1.1595 - accuracy: 0.5926\n",
      "Test accuracy: 0.593\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('20230714_21-50_fer_vggface-resnet50_finetuned_E16-VLoss0.99.keras')\n",
    "print(f\"Evaluating: {model_name}\")\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e0438",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "198a9f0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#(train_dataset, val_dataset), test_dataset = load_data(train_img_dir, test_img_dir)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m):\n\u001b[1;32m     21\u001b[0m         augmented_images \u001b[38;5;241m=\u001b[39m data_augmentation(images)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check Data Augmentation Layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomBrightness(.2),\n",
    "        layers.RandomContrast(.2),\n",
    "        layers.RandomZoom(.3, fill_mode=\"constant\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#(train_dataset, val_dataset), test_dataset = load_data(train_img_dir, test_img_dir)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ce91e6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44afb151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
