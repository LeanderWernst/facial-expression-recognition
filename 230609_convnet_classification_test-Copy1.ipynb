{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a80e2f",
   "metadata": {
    "id": "04a80e2f"
   },
   "source": [
    "# Instantiating Convulutional Network (convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f972a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1312bf24",
   "metadata": {
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1686662448577,
     "user": {
      "displayName": "Leander W",
      "userId": "17096542202881046225"
     },
     "user_tz": -120
    },
    "id": "1312bf24"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(224, 224, 3)) # width, height, channels\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\") (inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten() (x)\n",
    "outputs = layers.Dense(8, activation=\"softmax\")(x) # 8 classes in AffectNet\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f90ea8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1686662451338,
     "user": {
      "displayName": "Leander W",
      "userId": "17096542202881046225"
     },
     "user_tz": -120
    },
    "id": "17f90ea8",
    "outputId": "67cb907d-96e8-4d16-aca7-7d43212720f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 346112)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 2768904   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,862,152\n",
      "Trainable params: 2,862,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a34cb",
   "metadata": {
    "id": "c01a34cb"
   },
   "source": [
    "# Load AffectNet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8Y78wo4F6EoS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19677,
     "status": "ok",
     "timestamp": 1686662345726,
     "user": {
      "displayName": "Leander W",
      "userId": "17096542202881046225"
     },
     "user_tz": -120
    },
    "id": "8Y78wo4F6EoS",
    "outputId": "2dd3b2a2-6ada-46e1-c1c9-79d0bb64fda0"
   },
   "outputs": [],
   "source": [
    "# GDrive einbinden (falls on Colab)\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "640229c4",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1686662946037,
     "user": {
      "displayName": "Leander W",
      "userId": "17096542202881046225"
     },
     "user_tz": -120
    },
    "id": "640229c4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "\n",
    "# local\n",
    "train_img_dir = r'C:\\Users\\LEAND\\Coding\\_FER\\AffectNet\\train_set\\images'\n",
    "train_label_dir = r'C:\\Users\\LEAND\\Coding\\_FER\\AffectNet\\train_set\\annotations'\n",
    "test_img_dir = r'C:\\Users\\LEAND\\Coding\\_FER\\AffectNet\\val_set\\images'\n",
    "test_label_dir = r'C:\\Users\\LEAND\\Coding\\_FER\\AffectNet\\val_set\\annotations'\n",
    "\n",
    "# GDrive\n",
    "#train_img_dir = '/content/drive/Othercomputers/MeinComputer/_FER/AffectNet/train_set/images/'\n",
    "#train_label_dir = '/content/drive/Othercomputers/MeinComputer/_FER/AffectNet/train_set/annotations/'\n",
    "#test_img_dir = '/content/drive/Othercomputers/MeinComputer/_FER/AffectNet/val_set/images/'\n",
    "#test_label_dir = '/content/drive/Othercomputers/MeinComputer/_FER/AffectNet/val_set/annotations/'\n",
    "\n",
    "def load_data(train_img_dir, train_label_dir, test_img_dir, test_label_dir, limit_train=None, limit_test=None):\n",
    "    x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "    x_train_files = os.listdir(train_img_dir)\n",
    "    x_train_files = natsorted(x_train_files)\n",
    "\n",
    "    y_train_files = os.listdir(train_label_dir)\n",
    "    y_train_files = natsorted(y_train_files)\n",
    "\n",
    "    x_test_files = os.listdir(test_img_dir)\n",
    "    x_test_files = natsorted(x_test_files)\n",
    "\n",
    "    y_test_files = os.listdir(test_label_dir)\n",
    "    y_test_files = natsorted(y_test_files)\n",
    "\n",
    "    for i, file in enumerate(x_train_files):\n",
    "        if i == limit_train:\n",
    "            break\n",
    "        file_path = os.path.join(train_img_dir, file)\n",
    "        img = load_img(file_path)\n",
    "        data = img_to_array(img)\n",
    "        x_train.append(data)\n",
    "\n",
    "    for i, file in enumerate(y_train_files):\n",
    "        if i == limit_train * 4: # four files per image\n",
    "            break\n",
    "        if \"_exp.npy\" in file:\n",
    "            file_path = os.path.join(train_label_dir, file)\n",
    "            data = np.load(file_path)\n",
    "            y_train.append(data)\n",
    "\n",
    "    for i, file in enumerate(x_test_files):\n",
    "        if i == limit_test:\n",
    "            break\n",
    "        file_path = os.path.join(test_img_dir, file)\n",
    "        img = load_img(file_path)\n",
    "        data = img_to_array(img)\n",
    "        x_test.append(data)\n",
    "\n",
    "    for i, file in enumerate(y_test_files):\n",
    "        if i == limit_test:\n",
    "            break\n",
    "        if \"_exp.npy\" in file:\n",
    "            file_path = os.path.join(test_label_dir, file)\n",
    "            data = np.load(file_path)\n",
    "            y_test.append(data)\n",
    "\n",
    "    x_train, y_train, x_test, y_test = np.array(x_train), np.array(y_train).astype(int), np.array(x_test), np.array(y_test).astype(int)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50277c4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "executionInfo": {
     "elapsed": 9091,
     "status": "error",
     "timestamp": 1686662959187,
     "user": {
      "displayName": "Leander W",
      "userId": "17096542202881046225"
     },
     "user_tz": -120
    },
    "id": "50277c4b",
    "outputId": "731e759d-1330-4a73-e7e1-d4904fe794cc"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data(train_img_dir,\n",
    "                                                                     train_label_dir,\n",
    "                                                                     test_img_dir,\n",
    "                                                                     test_label_dir,\n",
    "                                                                     limit_train=10,\n",
    "                                                                     limit_test=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4951416e",
   "metadata": {
    "id": "4951416e",
    "outputId": "4843bc9e-fcab-4dc1-9982-1bf0518d9a92",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# learning-rate runter (optimizer)\n",
    "# batch-size erhöhen\n",
    "# validation set statt testset\n",
    "# model größer bauen bis overfitting, dann wieder langsam zurückbauen\n",
    "\n",
    "train_images = train_images.reshape((10, 224, 224, 3))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10, 224, 224, 3))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss = \"sparse_categorical_crossentropy\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=1, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "264945ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np   \n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "train_gen = DataGenerator(train_images, train_labels, 16)\n",
    "test_gen = DataGenerator(test_images, test_labels, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a517b23",
   "metadata": {
    "id": "2a517b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 18s 144ms/step - loss: 3.0008 - accuracy: 0.1250\n",
      "Test accuracy: 0.125\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
